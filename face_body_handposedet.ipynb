{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_holistic=mp.solutions.holistic\n",
    "mp_face_mesh=mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get realtime webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "while cam.isOpened():\n",
    "    ret,frame=cam.read()\n",
    "    \n",
    "    cv2.imshow('Holistic model detections',frame)\n",
    "    if cv2.waitKey(10) &0xFF==ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make detections from feed\n",
    "1.detect facial landmarks\n",
    "2.detect hand poses \n",
    "3.detect body poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    " while cam.isOpened():\n",
    "    ret,frame=cam.read()\n",
    "    frame=cv2.flip(frame,1)\n",
    "    image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    results=holistic.process(image)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # face,pose,left_hand,right hande landmarks\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks,mp_face_mesh.FACEMESH_TESSELATION,mp_drawing.DrawingSpec(color=(80,110,10),thickness=2,circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(80,256,121),thickness=1,circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,22,10),thickness=2,circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(80,44,121),thickness=2,circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(121,22,76),thickness=2,circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(121,44,250),thickness=2,circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))\n",
    "    \n",
    "    cv2.imshow('Holistic model detections',image)\n",
    "    if cv2.waitKey(10) &0xFF==ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are face landmarks,pose landmarks for body hands,hand landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For detecting multiple persons: we can use 'MultiPose' of mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose=mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(static_image_mode=False,model_complexity=2,enable_segmentation=True,min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cam.isOpened():\n",
    "        ret,frame=cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame=cv2.flip(frame,1)\n",
    "        \n",
    "        image=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results=pose.process(image)\n",
    "        image=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                       mp_drawing.DrawingSpec(color=(121,22,76),thickness=2,circle_radius=4),\n",
    "                                       mp_drawing.DrawingSpec(color=(121,44,250),thickness=2,circle_radius=2))\n",
    "        cv2.imshow('Multi-Person Pose Detection',image)\n",
    "        if cv2.waitKey(10) &0xFF==ord('q'):\n",
    "            break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58dd03c82a856a2c41288e86c367ed0bd38cf70c1a355097456901c82d37a119"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
